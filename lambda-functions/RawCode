import json
import boto3
import os
import re


def insert_msg_in_fifo_sqs_queue(event):
    
    print('Input event: {event}'.format(event=event))

    env = os.environ["ENV"].upper()
    
    client_name, project, client_s3_path, client_s3_key, client_s3_bucket = extract_data(event)
    risk_clients_list = ["vibra_risk","humana_risk","hpp_risk","uha_risk","priorityhealth_risk","hpn_risk","dean_mr_risk","ohi_risk","vnsny_risk","mdphycare_risk"]
    multiprojects_list = ["anthem"]
    
    should_proceed = filter_unknown_clients(client_name, project, env)
    copy_to_s3(client_s3_key,client_name,client_s3_bucket)
    
    if not should_proceed and ("risk" not in project.lower() and client_name not in risk_clients_list):
        message = 'Client Name: "{client_name}" and project "{project}" are not recognized. Skipping Client..'.format(client_name=client_name,project=project)
        print(message)
        publish_result(message, "Skipped Client", env)
        return

    data = {"client_name": client_name, "s3_input_path": client_s3_path}
    
    sqs = boto3.client('sqs')
    if client_name.lower() in [i.lower() for i in multiprojects_list] :
        response = sqs.send_message(
            QueueUrl=os.environ["MULTIPROJECT_PROCESSOR_QUEUE_URL"],
            MessageBody=json.dumps(data),
            MessageGroupId='MULTIPROJECT-PROCESSOR-QUEUE-GROUP'
        )
    else:
        response = sqs.send_message(
            QueueUrl=os.environ["PROCESSOR_QUEUE_URL"],
            MessageBody=json.dumps(data),
            MessageGroupId='PROCESSOR-QUEUE-GROUP'
        )        
    
    message = "Message published to etl dag queue.\nsqs message: {data}\nresponse: {response}".format(data=data,response=response)
    print(message)
    publish_result(message, "Success", env)

def extract_data(event):
    
    isSnsEvent = event['Records'][0].get("EventSource") == 'aws:sns'
    if isSnsEvent:
        event = json.loads(event['Records'][0]['Sns']['Message'])
        print('Extracted event: {event}'.format(event=event))
        
    client_s3_bucket = event['Records'][0]['s3']['bucket']['name']
    client_s3_key = event['Records'][0]['s3']['object']['key']
    
    if isSnsEvent:
        client_name = client_s3_bucket.split('-')[3]
    else:
        client_name = client_s3_key.split('/')[0]
        
    project = client_s3_key.split('/')[0]
    client_s3_key = re.search('^.*/',client_s3_key).group()[:-1]
    client_s3_path = 's3://' + client_s3_bucket + '/' + client_s3_key
    
    return client_name, project, client_s3_path, client_s3_key, client_s3_bucket
    
def filter_unknown_clients(client_name, project, env):
    
    file = open('client_project_lkp_{env}.json'.format(env=env))
    client_data = json.load(file)

    if len(client_data) == 0:
        return True
    
    match = next((d for d in client_data if d['client_name'].lower() == client_name.lower()), None)
    if match != None and project.lower() in [i.lower() for i in match['project_name']]:
        return True
        
    return False

def publish_result(message, result, env):
    sns = boto3.client('sns')
    att_dict = {}
    att_dict["resultValue"] = {'DataType': 'String', 'StringValue': result}
    response = sns.publish(
        TopicArn=os.environ["SNS_RESULT_TOPIC"],
        Subject='[{env}] ETL Lambda Result: {result}'.format(env=env,result=result),
        Message=message,
        MessageAttributes=att_dict
    )
    print(response)

def copy_to_s3(client_s3_key,client_name,client_s3_bucket):
    s3 = boto3.resource('s3')
    client_s3_bucket = s3.Bucket(client_s3_bucket)
    dest_s3_bucket_name = os.environ["DESNT_BUCKET"]
    dest_s3_bucket=s3.Bucket(dest_s3_bucket_name)
    source_path=client_s3_key+'/'
    destination_path=client_name+'/'
    for obj in client_s3_bucket.objects.filter(Prefix=source_path,Delimiter='/'):
        dest_object_name=obj.key.replace(source_path, '')
        dest_key=destination_path+dest_object_name
        print('copy file ' + dest_key)
        s3.Object(dest_s3_bucket.name, dest_key).copy_from(CopySource= {'Bucket': obj.bucket_name, 'Key': obj.key})

def lambda_handler(event, context):
    
    insert_msg_in_fifo_sqs_queue(event)

if __name__ == "__main__":
    lambda_handler(None,None)
